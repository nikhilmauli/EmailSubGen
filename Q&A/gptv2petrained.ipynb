{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9365100,"sourceType":"datasetVersion","datasetId":5678899}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-09-18T10:57:13.650600Z","iopub.execute_input":"2024-09-18T10:57:13.651598Z","iopub.status.idle":"2024-09-18T10:57:30.425944Z","shell.execute_reply.started":"2024-09-18T10:57:13.651555Z","shell.execute_reply":"2024-09-18T10:57:30.424806Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m640.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nInstalling collected packages: portalocker, sacrebleu, evaluate\nSuccessfully installed evaluate-0.4.3 portalocker-2.10.1 sacrebleu-2.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall -y transformers accelerate evaluate rouge_score\n!pip install transformers accelerate evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-09-18T10:57:30.428267Z","iopub.execute_input":"2024-09-18T10:57:30.429047Z","iopub.status.idle":"2024-09-18T10:58:03.456696Z","shell.execute_reply.started":"2024-09-18T10:57:30.429000Z","shell.execute_reply":"2024-09-18T10:58:03.455496Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.44.0\nUninstalling transformers-4.44.0:\n  Successfully uninstalled transformers-4.44.0\nFound existing installation: accelerate 0.33.0\nUninstalling accelerate-0.33.0:\n  Successfully uninstalled accelerate-0.33.0\nFound existing installation: evaluate 0.4.3\nUninstalling evaluate-0.4.3:\n  Successfully uninstalled evaluate-0.4.3\n\u001b[33mWARNING: Skipping rouge_score as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting transformers\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate\n  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\nCollecting evaluate\n  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hUsing cached evaluate-0.4.3-py3-none-any.whl (84 kB)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8a0689a476eaa2e6b366a30cf4883d472241d6ddee8fc75cabc5318350ae7db7\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, accelerate, transformers, evaluate\nSuccessfully installed accelerate-0.34.2 evaluate-0.4.3 rouge_score-0.1.2 transformers-4.44.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-09-18T10:58:03.458375Z","iopub.execute_input":"2024-09-18T10:58:03.458753Z","iopub.status.idle":"2024-09-18T10:59:44.864235Z","shell.execute_reply.started":"2024-09-18T10:58:03.458713Z","shell.execute_reply":"2024-09-18T10:59:44.863101Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nCollecting tensorflow\n  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nCollecting tensorboard<2.18,>=2.17 (from tensorflow)\n  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard, tensorflow\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.16.1\n    Uninstalling tensorflow-2.16.1:\n      Successfully uninstalled tensorflow-2.16.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.17.0 which is incompatible.\ntensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.17.0 which is incompatible.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorboard-2.17.1 tensorflow-2.17.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport re\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\nfrom transformers import DataCollatorForLanguageModeling\nfrom datasets import Dataset, DatasetDict\nimport evaluate\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-09-18T10:59:44.867449Z","iopub.execute_input":"2024-09-18T10:59:44.868122Z","iopub.status.idle":"2024-09-18T11:00:05.901118Z","shell.execute_reply.started":"2024-09-18T10:59:44.868082Z","shell.execute_reply":"2024-09-18T11:00:05.900247Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-09-18 10:59:53.825837: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-18 10:59:53.853979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-18 10:59:53.862718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ensure you are using the correct device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:05.902311Z","iopub.execute_input":"2024-09-18T11:00:05.902935Z","iopub.status.idle":"2024-09-18T11:00:05.965838Z","shell.execute_reply.started":"2024-09-18T11:00:05.902900Z","shell.execute_reply":"2024-09-18T11:00:05.964707Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import evaluate\nsacrebleu_metric = evaluate.load(\"sacrebleu\")\nrouge_metric = evaluate.load('rouge')","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:05.967136Z","iopub.execute_input":"2024-09-18T11:00:05.967446Z","iopub.status.idle":"2024-09-18T11:00:07.971214Z","shell.execute_reply.started":"2024-09-18T11:00:05.967413Z","shell.execute_reply":"2024-09-18T11:00:07.970433Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0195f634b9484354a28934f96babb832"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63991d6604a344f58b7c02d9a2cfdf6a"}},"metadata":{}}]},{"cell_type":"code","source":"import re\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:07.972423Z","iopub.execute_input":"2024-09-18T11:00:07.973439Z","iopub.status.idle":"2024-09-18T11:00:07.978060Z","shell.execute_reply.started":"2024-09-18T11:00:07.973392Z","shell.execute_reply":"2024-09-18T11:00:07.977154Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Function to move tensors to the correct device\ndef move_to_device(batch, device):\n    batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:07.979304Z","iopub.execute_input":"2024-09-18T11:00:07.979690Z","iopub.status.idle":"2024-09-18T11:00:07.991555Z","shell.execute_reply.started":"2024-09-18T11:00:07.979644Z","shell.execute_reply":"2024-09-18T11:00:07.990811Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def convert_csv_to_txt(csv_path, output_path, lowercase=False, clean=False):\n    with open(csv_path, 'r', encoding='windows-1252') as csv_file, open(output_path, 'w', encoding='utf-8') as txt_file:\n        csv_reader = csv.reader(csv_file)\n        header = next(csv_reader)\n\n        # Extracting the question and answer based on their header titles\n        question_idx = 0\n        answer_idx = 1\n        \n        for row in csv_reader:\n            question = row[question_idx].strip() if row[question_idx] else \"\"\n            answer = row[answer_idx].strip() if row[answer_idx] else \"\"\n\n            if lowercase:\n                question = question.lower()\n                answer = answer.lower()\n            if clean:\n                question = clean_text(question)\n                answer = clean_text(answer)\n\n            if question and answer:\n                txt_file.write(f\"Question: {question}\\nAnswer: {answer}\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:07.992719Z","iopub.execute_input":"2024-09-18T11:00:07.993156Z","iopub.status.idle":"2024-09-18T11:00:08.002741Z","shell.execute_reply.started":"2024-09-18T11:00:07.993124Z","shell.execute_reply":"2024-09-18T11:00:08.001895Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset_path ='/kaggle/input/qa-dataset'","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.007040Z","iopub.execute_input":"2024-09-18T11:00:08.007332Z","iopub.status.idle":"2024-09-18T11:00:08.014394Z","shell.execute_reply.started":"2024-09-18T11:00:08.007301Z","shell.execute_reply":"2024-09-18T11:00:08.013530Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import csv\n\n# Path to your CSV file\ncsv_path = dataset_path + '/train_1.csv'\n\n# Open the CSV file and print the header\nwith open(csv_path, 'r', encoding='windows-1252') as csv_file:\n    csv_reader = csv.reader(csv_file)\n    header = next(csv_reader)\n    print(\"CSV Header:\", header)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.015618Z","iopub.execute_input":"2024-09-18T11:00:08.016426Z","iopub.status.idle":"2024-09-18T11:00:08.042239Z","shell.execute_reply.started":"2024-09-18T11:00:08.016393Z","shell.execute_reply":"2024-09-18T11:00:08.041319Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"CSV Header: ['Question :What is the role of Siamese networks in domain adaptation?', 'Answer :Siamese networks can be used to align the representations of source and target domains by minimizing the discrepancy between them, making the model more robust to domain shifts.']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert CSV files to text format \nconvert_csv_to_txt(dataset_path + '/train_1.csv', 'train.txt', lowercase=True, clean=True)\nconvert_csv_to_txt(dataset_path + '/dev_1.csv', 'dev.txt', lowercase=True, clean=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.043276Z","iopub.execute_input":"2024-09-18T11:00:08.043557Z","iopub.status.idle":"2024-09-18T11:00:08.101444Z","shell.execute_reply.started":"2024-09-18T11:00:08.043522Z","shell.execute_reply":"2024-09-18T11:00:08.100717Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"convert_csv_to_txt(dataset_path + '/test_1.csv', 'test.txt', lowercase=True, clean=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.102382Z","iopub.execute_input":"2024-09-18T11:00:08.102656Z","iopub.status.idle":"2024-09-18T11:00:08.121787Z","shell.execute_reply.started":"2024-09-18T11:00:08.102626Z","shell.execute_reply":"2024-09-18T11:00:08.120912Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_txt_file = '/kaggle/working/train.txt'\ndev_txt_file = '/kaggle/working/dev.txt'\ntest_txt_file = '/kaggle/working/test.txt'","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.123135Z","iopub.execute_input":"2024-09-18T11:00:08.123408Z","iopub.status.idle":"2024-09-18T11:00:08.127740Z","shell.execute_reply.started":"2024-09-18T11:00:08.123378Z","shell.execute_reply":"2024-09-18T11:00:08.126759Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def load_txt_data(file_path):\n    questions = []\n    answers = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        content = f.read().split(\"\\n\\n\")  \n        for entry in content:\n            if \"Question:\" in entry and \"Answer:\" in entry:\n                question = re.search(r\"Question:(.+)\", entry)\n                answer = re.search(r\"Answer:(.+)\", entry)\n                if question and answer:\n                    questions.append(question.group(1).strip())\n                    answers.append(answer.group(1).strip())\n    return questions, answers","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.130567Z","iopub.execute_input":"2024-09-18T11:00:08.130880Z","iopub.status.idle":"2024-09-18T11:00:08.137438Z","shell.execute_reply.started":"2024-09-18T11:00:08.130850Z","shell.execute_reply":"2024-09-18T11:00:08.136598Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Load datasets\ntrain_questions, train_answers = load_txt_data('/kaggle/working/train.txt')\nval_questions, val_answers = load_txt_data('/kaggle/working/dev.txt')\ntest_questions, test_answers = load_txt_data('/kaggle/working/test.txt')\n\n# Convert to a format compatible with HuggingFace Dataset\ntrain_data = {\n    'question': train_questions,\n    'answer': train_answers\n}\n\nval_data = {\n    'question': val_questions,\n    'answer': val_answers\n}\n\ntest_data = {\n    'question': test_questions,\n    'answer': test_answers\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.138437Z","iopub.execute_input":"2024-09-18T11:00:08.138689Z","iopub.status.idle":"2024-09-18T11:00:08.161428Z","shell.execute_reply.started":"2024-09-18T11:00:08.138661Z","shell.execute_reply":"2024-09-18T11:00:08.160746Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(\"Number of train questions:\", len(train_questions))\nprint(\"Number of train answers:\", len(train_answers))\nprint(\"Number of val questions:\", len(val_questions))\nprint(\"Number of val answers:\", len(val_answers))\nprint(\"Number of val questions:\", len(test_questions))\nprint(\"Number of val answers:\", len(test_answers))","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.162457Z","iopub.execute_input":"2024-09-18T11:00:08.162739Z","iopub.status.idle":"2024-09-18T11:00:08.168507Z","shell.execute_reply.started":"2024-09-18T11:00:08.162709Z","shell.execute_reply":"2024-09-18T11:00:08.167603Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Number of train questions: 1984\nNumber of train answers: 1984\nNumber of val questions: 247\nNumber of val answers: 247\nNumber of val questions: 248\nNumber of val answers: 248\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.DataFrame(train_data)\nval_df = pd.DataFrame(val_data)\ntest_df = pd.DataFrame(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.169491Z","iopub.execute_input":"2024-09-18T11:00:08.169820Z","iopub.status.idle":"2024-09-18T11:00:08.187253Z","shell.execute_reply.started":"2024-09-18T11:00:08.169763Z","shell.execute_reply":"2024-09-18T11:00:08.186557Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)\nprint(val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.188432Z","iopub.execute_input":"2024-09-18T11:00:08.188804Z","iopub.status.idle":"2024-09-18T11:00:08.198957Z","shell.execute_reply.started":"2024-09-18T11:00:08.188745Z","shell.execute_reply":"2024-09-18T11:00:08.198104Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(1984, 2)\n(248, 2)\n(247, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert DataFrames to Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\ndatasets = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.200077Z","iopub.execute_input":"2024-09-18T11:00:08.200401Z","iopub.status.idle":"2024-09-18T11:00:08.275385Z","shell.execute_reply.started":"2024-09-18T11:00:08.200370Z","shell.execute_reply":"2024-09-18T11:00:08.274525Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.276508Z","iopub.execute_input":"2024-09-18T11:00:08.276820Z","iopub.status.idle":"2024-09-18T11:00:08.284148Z","shell.execute_reply.started":"2024-09-18T11:00:08.276788Z","shell.execute_reply":"2024-09-18T11:00:08.283235Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"1984"},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained tokenizer and model\nmodel_name='gpt2'\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:08.285064Z","iopub.execute_input":"2024-09-18T11:00:08.285624Z","iopub.status.idle":"2024-09-18T11:00:12.976213Z","shell.execute_reply.started":"2024-09-18T11:00:08.285579Z","shell.execute_reply":"2024-09-18T11:00:12.975302Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17a2c8ea515347cd85a20cd1195e3f71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d1b89a2776481aa3bbc1dda5735e7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cbf1536dd4b42999197692c19c7b0be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16033aed481a4c78a737af486fa982ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04dce56854d64e739d10f4aa5af48fba"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7c942987c95405da8edfade4eea9a6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b3a35624df43609445eb47ca91b5b2"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(data):\n    # Add a separator token between question and answer for clearer distinction\n    inputs = [f\"Question: {q} [SEP] Answer: {a}\" for q, a in zip(data['question'], data['answer'])]\n\n    # Dynamically adjust padding for efficiency in training\n    model_inputs = tokenizer(\n        inputs,\n        max_length=256,              # Truncate to 256 tokens max\n        truncation=True,             # Truncate long sequences\n        padding='max_length',        # Pad to max length or dynamically for batch padding\n        return_tensors=\"pt\"          # Return PyTorch tensors\n    )\n\n    # Create labels for the model, masking the padding tokens (-100)\n    labels = model_inputs['input_ids'].clone()\n    labels[labels == tokenizer.pad_token_id] = -100\n    model_inputs['labels'] = labels\n\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:12.977615Z","iopub.execute_input":"2024-09-18T11:00:12.978299Z","iopub.status.idle":"2024-09-18T11:00:12.986647Z","shell.execute_reply.started":"2024-09-18T11:00:12.978242Z","shell.execute_reply":"2024-09-18T11:00:12.985768Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = datasets['train'].map(preprocess_function, batched=True)\ntokenized_val_dataset = datasets['validation'].map(preprocess_function, batched=True)\n\n\n# Data Collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:00:12.988173Z","iopub.execute_input":"2024-09-18T11:00:12.988570Z","iopub.status.idle":"2024-09-18T11:00:19.311948Z","shell.execute_reply.started":"2024-09-18T11:00:12.988526Z","shell.execute_reply":"2024-09-18T11:00:19.311014Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1984 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ef7542fa2a2441eb1e2736c28e15391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/247 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"910d8dde8ad0429a85e2416d8ba43a33"}},"metadata":{}}]},{"cell_type":"code","source":"# Training Arguments\ntraining_args = TrainingArguments(\n       evaluation_strategy=\"epoch\",\n    output_dir='./results',\n    overwrite_output_dir=True,\n    learning_rate=1e-5,                 # Lower learning rate for more stable training\n    per_device_train_batch_size=1,      # Tune based on your GPU memory\n    per_device_eval_batch_size=1,\n    num_train_epochs=10,               \n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    logging_dir='./logs',\n    logging_steps=100,\n    warmup_steps=50,                   \n    weight_decay=0.01,                  \n    gradient_accumulation_steps=2\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=None\n)\n\n# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:40:56.952516Z","iopub.execute_input":"2024-09-18T11:40:56.952916Z","iopub.status.idle":"2024-09-18T12:17:32.480875Z","shell.execute_reply.started":"2024-09-18T11:40:56.952877Z","shell.execute_reply":"2024-09-18T12:17:32.479811Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4960' max='4960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4960/4960 36:34, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.101000</td>\n      <td>2.135743</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.945600</td>\n      <td>2.113733</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.880500</td>\n      <td>2.089173</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.761400</td>\n      <td>2.078348</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.783700</td>\n      <td>2.065639</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.715800</td>\n      <td>2.058012</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.665500</td>\n      <td>2.058289</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.673100</td>\n      <td>2.057099</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.605300</td>\n      <td>2.057893</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.637500</td>\n      <td>2.058245</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4960, training_loss=1.789415648675734, metrics={'train_runtime': 2194.852, 'train_samples_per_second': 9.039, 'train_steps_per_second': 2.26, 'total_flos': 2592016957440000.0, 'train_loss': 1.789415648675734, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"./results/final_model\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:08.093718Z","iopub.execute_input":"2024-09-18T12:18:08.094188Z","iopub.status.idle":"2024-09-18T12:18:09.663793Z","shell.execute_reply.started":"2024-09-18T12:18:08.094146Z","shell.execute_reply":"2024-09-18T12:18:09.662844Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"!zip -r /kaggle/working/results/final_model.zip /kaggle/working/results/final_model","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:09.666147Z","iopub.execute_input":"2024-09-18T12:18:09.666604Z","iopub.status.idle":"2024-09-18T12:18:37.150515Z","shell.execute_reply.started":"2024-09-18T12:18:09.666552Z","shell.execute_reply":"2024-09-18T12:18:37.149408Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"updating: kaggle/working/results/final_model/ (stored 0%)\nupdating: kaggle/working/results/final_model/tokenizer_config.json (deflated 55%)\nupdating: kaggle/working/results/final_model/special_tokens_map.json (deflated 74%)\nupdating: kaggle/working/results/final_model/training_args.bin (deflated 51%)\nupdating: kaggle/working/results/final_model/model.safetensors (deflated 7%)\nupdating: kaggle/working/results/final_model/vocab.json (deflated 68%)\nupdating: kaggle/working/results/final_model/generation_config.json (deflated 24%)\nupdating: kaggle/working/results/final_model/config.json (deflated 50%)\nupdating: kaggle/working/results/final_model/merges.txt (deflated 53%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from safetensors.torch import load_file as load_safetensors\nmodel_name='gpt2'\nmodel_path = \"/kaggle/working/results/final_model\"\nstate_dict = load_safetensors(f\"{model_path}/model.safetensors\")\nmodel = GPT2LMHeadModel.from_pretrained(model_path, state_dict=state_dict)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:37.513232Z","iopub.execute_input":"2024-09-18T12:18:37.513700Z","iopub.status.idle":"2024-09-18T12:18:37.796891Z","shell.execute_reply.started":"2024-09-18T12:18:37.513646Z","shell.execute_reply":"2024-09-18T12:18:37.795801Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:37.798980Z","iopub.execute_input":"2024-09-18T12:18:37.801346Z","iopub.status.idle":"2024-09-18T12:18:38.167442Z","shell.execute_reply.started":"2024-09-18T12:18:37.801310Z","shell.execute_reply":"2024-09-18T12:18:38.166286Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Set pad_token to eos_token if it's not already set\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:38.168806Z","iopub.execute_input":"2024-09-18T12:18:38.169157Z","iopub.status.idle":"2024-09-18T12:18:38.174662Z","shell.execute_reply.started":"2024-09-18T12:18:38.169119Z","shell.execute_reply":"2024-09-18T12:18:38.173812Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def generate_text(sequence, max_new_tokens=50):\n    # Encode the input sequence and move it to the correct device\n    inputs = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True)\n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs.get('attention_mask', None).to(device)  # Get attention mask if available\n\n    # Ensure the model is on the same device\n    model.to(device)\n\n    # Generate text with the model\n    try:\n        output = model.generate(\n            input_ids,\n            attention_mask=attention_mask,\n            do_sample=True,\n            max_length=input_ids.size(1) + max_new_tokens,\n            pad_token_id=tokenizer.pad_token_id,  # Ensure this is set correctly\n            temperature=1.0,  # Control randomness\n            top_k=50,        # Control diversity\n            top_p=0.95       # Control diversity\n        )\n        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n        return generated_text\n    except Exception as e:\n        print(f\"Error during text generation: {e}\")\n        return \"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:38.175859Z","iopub.execute_input":"2024-09-18T12:18:38.176183Z","iopub.status.idle":"2024-09-18T12:18:38.189757Z","shell.execute_reply.started":"2024-09-18T12:18:38.176150Z","shell.execute_reply":"2024-09-18T12:18:38.188712Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def question_answer(question, max_new_tokens=150, stop_token=\"Answer:\"):\n    # Ensure the model is in evaluation mode and on the correct device\n    model.eval()\n    model.to(device)  # Move model to the correct device (GPU or CPU)\n    \n    # Prepare the input prompt\n    prompt = f\"Question: {question} Answer:\"\n    \n    # Tokenize the prompt and ensure the tensors are on the same device as the model\n    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(device)\n    \n    try:\n        # Generate the output from the model\n        output = model.generate(\n            input_ids=inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            max_length=inputs['input_ids'].size(1) + max_new_tokens,\n            pad_token_id=tokenizer.pad_token_id,\n            temperature=1.0,\n            top_k=50,\n            top_p=0.95,\n            do_sample=True,\n            eos_token_id=tokenizer.eos_token_id  # Stop at the end of the sequence\n        )\n\n        # Decode the generated output\n        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n        \n        # Extract only the answer from the generated text\n        generated_answer = generated_text.replace(f\"Question: {question} Answer:\", \"\").strip()\n        \n        # Stop answer generation at the first occurrence of the stop token\n        if stop_token in generated_answer:\n            generated_answer = generated_answer.split(stop_token)[0].strip()\n\n        return generated_answer\n\n    except Exception as e:\n        print(f\"Error during text generation: {e}\")\n        return \"\"\n\n# Test the function\nprint(question_answer(\"What is feature engineering for unstructured data?\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:38.191014Z","iopub.execute_input":"2024-09-18T12:18:38.192254Z","iopub.status.idle":"2024-09-18T12:18:39.844042Z","shell.execute_reply.started":"2024-09-18T12:18:38.192192Z","shell.execute_reply":"2024-09-18T12:18:39.842868Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"answer feature engineering for unstructured data helps prevent overfitting by leveraging knowledge learned in unstructured data by using techniques like crossvalidation and machine translation to improve model stability and reduce overfitting by leveraging insights learned in unlabelled data from previous iterations of the same model on new datasets often involving additional validation to see if the model performs well across different training sets or epochs providing a more robust evaluation metric for future training on unlabelled data by capturing the underlying patterns and guiding the model through multiple iterations of the same model training this is a powerful tool for unstructured data where the model is trained and tested on multiple datasets with varied features before making an immediate decision on which dataset should be used for feature engineering in unstructured data by\n","output_type":"stream"}]},{"cell_type":"code","source":"question_answer('What is the mean absolute error (MAE)?')","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:39.845440Z","iopub.execute_input":"2024-09-18T12:18:39.845800Z","iopub.status.idle":"2024-09-18T12:18:41.350344Z","shell.execute_reply.started":"2024-09-18T12:18:39.845752Z","shell.execute_reply":"2024-09-18T12:18:41.349123Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"'Answer the mean absolute error is the mean absolute error squared or a sigmoid function that shows the mean absolute error squared or a sigmoid function that shows the average absolute error squared or a sigmoid function that shows the average absolute error squared for the entire dataset where the variance is small a sigmoid function returns true or false indicating the mean absolute error and the mean absolute error is the absolute value indicating the average absolute error indicating the average absolute error squared for the entire dataset where the variance is high a sigmoid function returns false indicating invalid samples the mean absolute error was obtained from a dataset with more than one duplicate samples instead of a large number of samples indicating that the dataset did not belong to the same class or group as the general'"},"metadata":{}}]},{"cell_type":"code","source":"print(question_answer('What is Q-Learning and how does it work?'))","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:41.351881Z","iopub.execute_input":"2024-09-18T12:18:41.352325Z","iopub.status.idle":"2024-09-18T12:18:42.870234Z","shell.execute_reply.started":"2024-09-18T12:18:41.352267Z","shell.execute_reply":"2024-09-18T12:18:42.869117Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Answer Qlearning is a supervised learning algorithm that learns a random set of data by randomly generating new data samples to represent the input data points at the inception of the experiment it iterates through the training data before confirming that the new data points have been correctly labeled by the training data and making predictions about the new data points within a specific learning time step this approach is known as supervised learning and is used in several models including the reinforcement learning models kink task and sentiment analysis model to learn from examples such as f1 reward and cnns tasks these methods are used to learn from examples of human intelligence improving the learning process for both agents and their agents learning rate and accuracy are another important factor in this classifier qlearning aims to extract knowledge from examples and\n","output_type":"stream"}]},{"cell_type":"code","source":"question_answer('What is the difference between BERT and RoBERTa?')","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:21:48.604450Z","iopub.execute_input":"2024-09-18T12:21:48.605156Z","iopub.status.idle":"2024-09-18T12:21:50.069236Z","shell.execute_reply.started":"2024-09-18T12:21:48.605115Z","shell.execute_reply":"2024-09-18T12:21:50.068092Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"'Answer the difference between the two is the difference in the approach between bert and robert making it more efficient but slower at training and helping to reduce overfitting on smaller datasets while bert is more expensive but faster on larger datasets it is more tolerant of smaller errors and can handle large dataset size this helps in improving model performance both models can learn fast and penalize overfitting if they are not careful and adjust for local variations in the training data this is especially useful when dealing with larger datasets and large datasets these tools can be combined to improve model performance and reduce overfitting especially useful if you are trying to balance two or more training sets with training data but you can skip both methods and use different approaches depending on what is important to you at the'"},"metadata":{}}]},{"cell_type":"code","source":"question_answer(\"What is the primary function of a Generative Adversarial Network (GAN)?\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:44.371036Z","iopub.execute_input":"2024-09-18T12:18:44.371367Z","iopub.status.idle":"2024-09-18T12:18:45.919482Z","shell.execute_reply.started":"2024-09-18T12:18:44.371330Z","shell.execute_reply":"2024-09-18T12:18:45.918367Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'answer the main function of the gan is to select the most probable outcomes from the nlp input and update the decision tree during training boosting to maximize future rewards over predictions derived from earlier predictions enabling the network to learn robust representations of data during exploration and exploitation of hidden environments enabling exploration in both training and exploitation of unseen or corrupt data by exploiting unseen entities such as data stored in the network storage environment the main contribution is provided by the f1 function which updates the decision tree during training updating the decision trees weights and updates the entropy of the input data ensuring better prediction accuracy for unseen data that can be reused during exploitation of hidden or corrupt data by exploiting unseen or corrupted inputs training the f1 function updates the decision tree at each step ensuring better generalization to'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_answer(\"What Optimization Algorithms are available in Scikit-Learn?\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:22:53.947406Z","iopub.execute_input":"2024-09-18T12:22:53.948142Z","iopub.status.idle":"2024-09-18T12:22:55.456540Z","shell.execute_reply.started":"2024-09-18T12:22:53.948103Z","shell.execute_reply":"2024-09-18T12:22:55.455210Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"'this page highlights a few optimization algorithms that are available in machine learning including ensemble methods pca gradient descent and tdp gradient descent with several key features including multilayer regularization and l1 recurrent neural network architectures using a variety of techniques including bert gradient descent and pca weighted sum using tdp weighted sum using kmeriket weights which can optimize model performance for sequences that are not explicitly labeled and those that are not explicitly labeled and that feature principal components are not fully separable from the rest of the data the selection criteria can be used for specific sequences including regularization or l1 recurrent neural network architectures like gaussian and sigmoid neural networks with a maximum margin and few outliers reducing the need for specialized techniques like kmeriket'"},"metadata":{}}]},{"cell_type":"code","source":"question_answer(\"What is machine learning?\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:47.413038Z","iopub.execute_input":"2024-09-18T12:18:47.413438Z","iopub.status.idle":"2024-09-18T12:18:48.908407Z","shell.execute_reply.started":"2024-09-18T12:18:47.413392Z","shell.execute_reply":"2024-09-18T12:18:48.907330Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"'machine learning refers to artificial intelligence algorithms that learn and interpret human behavior from trained data or data sources to achieve desired outcomes or improve overall performance or overall performance in certain domains or tasks using techniques including reinforcement learning self attention learning and deep learning algorithms for example machine learning for self attention and attentional coordination and learning in natural language processing for visual recognition and for natural language processing for sentiment analysis and recommendation systems in decision trees and conversational assistants such as word2vec and bartortone ensembles are primarily used for this type of classification tasks but there are a limited number of applications including natural language processing task recognition machine translation feature extraction feature selection and prediction language processing for word2vec and bartortone ensembles can perform tasks as varied as translation for recognizing'"},"metadata":{}}]},{"cell_type":"code","source":"question_answer('Does the Squeeze function in Numpy remove all redundant dimensions by default?')","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:48.909877Z","iopub.execute_input":"2024-09-18T12:18:48.910277Z","iopub.status.idle":"2024-09-18T12:18:50.435707Z","shell.execute_reply.started":"2024-09-18T12:18:48.910222Z","shell.execute_reply":"2024-09-18T12:18:50.434541Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"'yes yes yes no this function takes a regularized dimension function and maps it to a value using an lstms function it returns a linear combination of the two which means that the loss function in any dimension is reduced to a smaller minimum to preserve the maximum precision for the nearest neighbors this makes it possible for more complex problem areas to fit more densely into larger dimensions providing more expressive representations of the class features that can be represented as single samples of a larger range of features and help reduce the number of dimensionality violations this feature ensures that the kernel of a feature map is small and the information that is retained helps us detect potential overfitting and reduce the size of the feature space often resulting in better classification accuracy and better performance on higherdimensional data as these metrics'"},"metadata":{}}]},{"cell_type":"code","source":"# Ensure the clean_answer function is defined\ndef clean_answer(answer):\n    return answer.strip().lower()\n\n# Generate predictions for the test set\npredicted_answers = [question_answer(q, max_new_tokens=50) for q in test_questions]\n\n# Clean test answers\ntest_answers_cleaned = [clean_answer(a) for a in test_answers]\n\n# Check if the lengths match\nif len(predicted_answers) == len(test_answers_cleaned):\n    # Compute ROUGE scores\n    rouge_results = rouge.compute(predictions=predicted_answers, references=test_answers_cleaned)\n    \n    # Display ROUGE Scores\n    print(\"ROUGE Scores:\")\n    for rouge_type, score in rouge_results.items():\n        print(f\"{rouge_type}: {score}\")\nelse:\n    print(\"Error: The number of predicted answers and test answers do not match.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T12:18:50.437504Z","iopub.execute_input":"2024-09-18T12:18:50.438128Z","iopub.status.idle":"2024-09-18T12:20:54.668524Z","shell.execute_reply.started":"2024-09-18T12:18:50.438078Z","shell.execute_reply":"2024-09-18T12:20:54.667467Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"ROUGE Scores:\nrouge1: 0.2531865687054879\nrouge2: 0.07329226163268776\nrougeL: 0.20524351443889402\nrougeLsum: 0.20490695373692563\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}