{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9365100,"sourceType":"datasetVersion","datasetId":5678899}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:34:41.956889Z","iopub.execute_input":"2024-09-15T06:34:41.957263Z","iopub.status.idle":"2024-09-15T06:34:57.343160Z","shell.execute_reply.started":"2024-09-15T06:34:41.957228Z","shell.execute_reply":"2024-09-15T06:34:57.342045Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m868.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nInstalling collected packages: portalocker, sacrebleu, evaluate\nSuccessfully installed evaluate-0.4.3 portalocker-2.10.1 sacrebleu-2.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall -y transformers accelerate evaluate rouge_score\n!pip install transformers accelerate evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:34:57.345785Z","iopub.execute_input":"2024-09-15T06:34:57.346234Z","iopub.status.idle":"2024-09-15T06:35:27.415958Z","shell.execute_reply.started":"2024-09-15T06:34:57.346187Z","shell.execute_reply":"2024-09-15T06:35:27.415034Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.44.0\nUninstalling transformers-4.44.0:\n  Successfully uninstalled transformers-4.44.0\nFound existing installation: accelerate 0.33.0\nUninstalling accelerate-0.33.0:\n  Successfully uninstalled accelerate-0.33.0\nFound existing installation: evaluate 0.4.3\nUninstalling evaluate-0.4.3:\n  Successfully uninstalled evaluate-0.4.3\n\u001b[33mWARNING: Skipping rouge_score as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting transformers\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m635.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting accelerate\n  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\nCollecting evaluate\n  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hUsing cached evaluate-0.4.3-py3-none-any.whl (84 kB)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=3d4ef617846a0c3eaab3becc48077072285d81de5c23a7934907111e69059751\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, accelerate, transformers, evaluate\nSuccessfully installed accelerate-0.34.2 evaluate-0.4.3 rouge_score-0.1.2 transformers-4.44.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:35:27.417347Z","iopub.execute_input":"2024-09-15T06:35:27.417673Z","iopub.status.idle":"2024-09-15T06:36:46.608121Z","shell.execute_reply.started":"2024-09-15T06:35:27.417641Z","shell.execute_reply":"2024-09-15T06:36:46.607214Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nCollecting tensorflow\n  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nCollecting tensorboard<2.18,>=2.17 (from tensorflow)\n  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard, tensorflow\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.16.1\n    Uninstalling tensorflow-2.16.1:\n      Successfully uninstalled tensorflow-2.16.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.17.0 which is incompatible.\ntensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.17.0 which is incompatible.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorboard-2.17.1 tensorflow-2.17.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport re\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\nfrom transformers import DataCollatorForLanguageModeling\nfrom datasets import Dataset, DatasetDict\nimport evaluate\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:36:46.609744Z","iopub.execute_input":"2024-09-15T06:36:46.610140Z","iopub.status.idle":"2024-09-15T06:37:00.148935Z","shell.execute_reply.started":"2024-09-15T06:36:46.610098Z","shell.execute_reply":"2024-09-15T06:37:00.148144Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-09-15 06:36:52.050221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-15 06:36:52.072357: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-15 06:36:52.080561: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ensure you are using the correct device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:00.151186Z","iopub.execute_input":"2024-09-15T06:37:00.151780Z","iopub.status.idle":"2024-09-15T06:37:00.210682Z","shell.execute_reply.started":"2024-09-15T06:37:00.151745Z","shell.execute_reply":"2024-09-15T06:37:00.209596Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import evaluate\nsacrebleu_metric = evaluate.load(\"sacrebleu\")\nrouge_metric = evaluate.load('rouge')","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:00.211991Z","iopub.execute_input":"2024-09-15T06:37:00.212377Z","iopub.status.idle":"2024-09-15T06:37:01.580148Z","shell.execute_reply.started":"2024-09-15T06:37:00.212328Z","shell.execute_reply":"2024-09-15T06:37:01.579375Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"225bc4143ef84263833680bcf8345756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3673fc29c9c24c2a8320880cc3ac611a"}},"metadata":{}}]},{"cell_type":"code","source":"import re\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:06:59.549888Z","iopub.execute_input":"2024-09-15T07:06:59.550273Z","iopub.status.idle":"2024-09-15T07:06:59.556735Z","shell.execute_reply.started":"2024-09-15T07:06:59.550240Z","shell.execute_reply":"2024-09-15T07:06:59.555300Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Function to move tensors to the correct device\ndef move_to_device(batch, device):\n    batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.588781Z","iopub.execute_input":"2024-09-15T06:37:01.589151Z","iopub.status.idle":"2024-09-15T06:37:01.597198Z","shell.execute_reply.started":"2024-09-15T06:37:01.589119Z","shell.execute_reply":"2024-09-15T06:37:01.596326Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def convert_csv_to_txt(csv_path, output_path, lowercase=False, clean=False):\n    with open(csv_path, 'r', encoding='windows-1252') as csv_file, open(output_path, 'w', encoding='utf-8') as txt_file:\n        csv_reader = csv.reader(csv_file)\n        header = next(csv_reader)\n\n        # Extracting the question and answer based on their header titles\n        question_idx = 0\n        answer_idx = 1\n        \n        for row in csv_reader:\n            question = row[question_idx].strip() if row[question_idx] else \"\"\n            answer = row[answer_idx].strip() if row[answer_idx] else \"\"\n\n            if lowercase:\n                question = question.lower()\n                answer = answer.lower()\n            if clean:\n                question = clean_text(question)\n                answer = clean_text(answer)\n\n            if question and answer:\n                txt_file.write(f\"Question: {question}\\nAnswer: {answer}\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.598332Z","iopub.execute_input":"2024-09-15T06:37:01.598714Z","iopub.status.idle":"2024-09-15T06:37:01.606419Z","shell.execute_reply.started":"2024-09-15T06:37:01.598650Z","shell.execute_reply":"2024-09-15T06:37:01.605657Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset_path ='/kaggle/input/qa-dataset'","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.607318Z","iopub.execute_input":"2024-09-15T06:37:01.607622Z","iopub.status.idle":"2024-09-15T06:37:01.613991Z","shell.execute_reply.started":"2024-09-15T06:37:01.607592Z","shell.execute_reply":"2024-09-15T06:37:01.613224Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import csv\n\n# Path to your CSV file\ncsv_path = dataset_path + '/train_1.csv'\n\n# Open the CSV file and print the header\nwith open(csv_path, 'r', encoding='windows-1252') as csv_file:\n    csv_reader = csv.reader(csv_file)\n    header = next(csv_reader)\n    print(\"CSV Header:\", header)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.615036Z","iopub.execute_input":"2024-09-15T06:37:01.615309Z","iopub.status.idle":"2024-09-15T06:37:01.627959Z","shell.execute_reply.started":"2024-09-15T06:37:01.615280Z","shell.execute_reply":"2024-09-15T06:37:01.626940Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"CSV Header: ['Question :What is the role of Siamese networks in domain adaptation?', 'Answer :Siamese networks can be used to align the representations of source and target domains by minimizing the discrepancy between them, making the model more robust to domain shifts.']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert CSV files to text format \nconvert_csv_to_txt(dataset_path + '/train_1.csv', 'train.txt', lowercase=True, clean=True)\nconvert_csv_to_txt(dataset_path + '/dev_1.csv', 'dev.txt', lowercase=True, clean=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.629054Z","iopub.execute_input":"2024-09-15T06:37:01.629329Z","iopub.status.idle":"2024-09-15T06:37:01.677468Z","shell.execute_reply.started":"2024-09-15T06:37:01.629300Z","shell.execute_reply":"2024-09-15T06:37:01.676572Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"convert_csv_to_txt(dataset_path + '/test_1.csv', 'test.txt', lowercase=True, clean=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.678810Z","iopub.execute_input":"2024-09-15T06:37:01.679107Z","iopub.status.idle":"2024-09-15T06:37:01.692269Z","shell.execute_reply.started":"2024-09-15T06:37:01.679075Z","shell.execute_reply":"2024-09-15T06:37:01.691430Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_txt_file = '/kaggle/working/train.txt'\ndev_txt_file = '/kaggle/working/dev.txt'\ntest_txt_file = '/kaggle/working/test.txt'","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.697536Z","iopub.execute_input":"2024-09-15T06:37:01.697885Z","iopub.status.idle":"2024-09-15T06:37:01.702073Z","shell.execute_reply.started":"2024-09-15T06:37:01.697854Z","shell.execute_reply":"2024-09-15T06:37:01.701012Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def load_txt_data(file_path):\n    questions = []\n    answers = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        content = f.read().split(\"\\n\\n\")  \n        for entry in content:\n            if \"Question:\" in entry and \"Answer:\" in entry:\n                question = re.search(r\"Question:(.+)\", entry)\n                answer = re.search(r\"Answer:(.+)\", entry)\n                if question and answer:\n                    questions.append(question.group(1).strip())\n                    answers.append(answer.group(1).strip())\n    return questions, answers","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.703414Z","iopub.execute_input":"2024-09-15T06:37:01.703811Z","iopub.status.idle":"2024-09-15T06:37:01.710811Z","shell.execute_reply.started":"2024-09-15T06:37:01.703765Z","shell.execute_reply":"2024-09-15T06:37:01.709932Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Load datasets\ntrain_questions, train_answers = load_txt_data('/kaggle/working/train.txt')\nval_questions, val_answers = load_txt_data('/kaggle/working/dev.txt')\ntest_questions, test_answers = load_txt_data('/kaggle/working/test.txt')\n\n# Convert to a format compatible with HuggingFace Dataset\ntrain_data = {\n    'question': train_questions,\n    'answer': train_answers\n}\n\nval_data = {\n    'question': val_questions,\n    'answer': val_answers\n}\n\ntest_data = {\n    'question': test_questions,\n    'answer': test_answers\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.711834Z","iopub.execute_input":"2024-09-15T06:37:01.712101Z","iopub.status.idle":"2024-09-15T06:37:01.731439Z","shell.execute_reply.started":"2024-09-15T06:37:01.712072Z","shell.execute_reply":"2024-09-15T06:37:01.730772Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(\"Number of train questions:\", len(train_questions))\nprint(\"Number of train answers:\", len(train_answers))\nprint(\"Number of val questions:\", len(val_questions))\nprint(\"Number of val answers:\", len(val_answers))\nprint(\"Number of val questions:\", len(test_questions))\nprint(\"Number of val answers:\", len(test_answers))","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.732324Z","iopub.execute_input":"2024-09-15T06:37:01.732622Z","iopub.status.idle":"2024-09-15T06:37:01.738611Z","shell.execute_reply.started":"2024-09-15T06:37:01.732592Z","shell.execute_reply":"2024-09-15T06:37:01.737562Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Number of train questions: 1984\nNumber of train answers: 1984\nNumber of val questions: 247\nNumber of val answers: 247\nNumber of val questions: 248\nNumber of val answers: 248\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.DataFrame(train_data)\nval_df = pd.DataFrame(val_data)\ntest_df = pd.DataFrame(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.739826Z","iopub.execute_input":"2024-09-15T06:37:01.740293Z","iopub.status.idle":"2024-09-15T06:37:01.750107Z","shell.execute_reply.started":"2024-09-15T06:37:01.740251Z","shell.execute_reply":"2024-09-15T06:37:01.749303Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)\nprint(val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.751175Z","iopub.execute_input":"2024-09-15T06:37:01.752075Z","iopub.status.idle":"2024-09-15T06:37:01.759331Z","shell.execute_reply.started":"2024-09-15T06:37:01.752031Z","shell.execute_reply":"2024-09-15T06:37:01.758439Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(1984, 2)\n(248, 2)\n(247, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert DataFrames to Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\ndatasets = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.760417Z","iopub.execute_input":"2024-09-15T06:37:01.760801Z","iopub.status.idle":"2024-09-15T06:37:01.806435Z","shell.execute_reply.started":"2024-09-15T06:37:01.760741Z","shell.execute_reply":"2024-09-15T06:37:01.805727Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.807452Z","iopub.execute_input":"2024-09-15T06:37:01.807818Z","iopub.status.idle":"2024-09-15T06:37:01.814692Z","shell.execute_reply.started":"2024-09-15T06:37:01.807777Z","shell.execute_reply":"2024-09-15T06:37:01.813726Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"1984"},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained tokenizer and model\nmodel_name='gpt2'\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:01.816093Z","iopub.execute_input":"2024-09-15T06:37:01.816737Z","iopub.status.idle":"2024-09-15T06:37:06.099595Z","shell.execute_reply.started":"2024-09-15T06:37:01.816694Z","shell.execute_reply":"2024-09-15T06:37:06.098501Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e29ad73ddd24b2b86f7c0a3e8f13c82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f5005652df4ca1afdf44c96164932c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d135a8ab13ae431cbf62a701d59af901"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c857b3db6df41af8f5f4d7e12415e98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffcc5deda3f048ef978dd04ce9d1b436"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1e255c35e2d43c1b9ce9fa0bd76caae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"730a50ad7c144505bdafca25a95df82b"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(data):\n    # Add a separator token between question and answer for clearer distinction\n    inputs = [f\"Question: {q} [SEP] Answer: {a}\" for q, a in zip(data['question'], data['answer'])]\n\n    # Dynamically adjust padding for efficiency in training\n    model_inputs = tokenizer(\n        inputs,\n        max_length=256,              # Truncate to 256 tokens max\n        truncation=True,             # Truncate long sequences\n        padding='max_length',        # Pad to max length or dynamically for batch padding\n        return_tensors=\"pt\"          # Return PyTorch tensors\n    )\n\n    # Create labels for the model, masking the padding tokens (-100)\n    labels = model_inputs['input_ids'].clone()\n    labels[labels == tokenizer.pad_token_id] = -100\n    model_inputs['labels'] = labels\n\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:06.101627Z","iopub.execute_input":"2024-09-15T06:37:06.102389Z","iopub.status.idle":"2024-09-15T06:37:06.108888Z","shell.execute_reply.started":"2024-09-15T06:37:06.102335Z","shell.execute_reply":"2024-09-15T06:37:06.108242Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = datasets['train'].map(preprocess_function, batched=True)\ntokenized_val_dataset = datasets['validation'].map(preprocess_function, batched=True)\n\n\n# Data Collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:06.109884Z","iopub.execute_input":"2024-09-15T06:37:06.110728Z","iopub.status.idle":"2024-09-15T06:37:13.363660Z","shell.execute_reply.started":"2024-09-15T06:37:06.110694Z","shell.execute_reply":"2024-09-15T06:37:13.362712Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1984 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e10fa4f393041efbeb30d2841bdbf20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/247 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0571e74634043a2a27169c59f981168"}},"metadata":{}}]},{"cell_type":"code","source":"# Training Arguments\ntraining_args = TrainingArguments(\n       evaluation_strategy=\"epoch\",\n    output_dir='./results',\n    overwrite_output_dir=True,\n    learning_rate=3e-5,                 # Lower learning rate for more stable training\n    per_device_train_batch_size=4,      # Tune based on your GPU memory\n    per_device_eval_batch_size=4,\n    num_train_epochs=10,               \n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    logging_dir='./logs',\n    logging_steps=100,\n    warmup_steps=200,                   \n    weight_decay=0.01,                  \n    gradient_accumulation_steps=2\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=None\n)\n\n# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:37:13.364922Z","iopub.execute_input":"2024-09-15T06:37:13.365693Z","iopub.status.idle":"2024-09-15T06:55:59.644692Z","shell.execute_reply.started":"2024-09-15T06:37:13.365657Z","shell.execute_reply":"2024-09-15T06:55:59.643810Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240915_063727-9dyqfgfw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/abcdkgf993-aiml/huggingface/runs/9dyqfgfw' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/abcdkgf993-aiml/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/abcdkgf993-aiml/huggingface' target=\"_blank\">https://wandb.ai/abcdkgf993-aiml/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/abcdkgf993-aiml/huggingface/runs/9dyqfgfw' target=\"_blank\">https://wandb.ai/abcdkgf993-aiml/huggingface/runs/9dyqfgfw</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1240/1240 18:12, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.181600</td>\n      <td>2.853980</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.944100</td>\n      <td>2.544305</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.651400</td>\n      <td>2.428147</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.550700</td>\n      <td>2.367625</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.388000</td>\n      <td>2.327686</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.341500</td>\n      <td>2.300028</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.317200</td>\n      <td>2.283758</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.276500</td>\n      <td>2.272247</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.231900</td>\n      <td>2.265594</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.239000</td>\n      <td>2.263248</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1240, training_loss=2.55921747761388, metrics={'train_runtime': 1124.5758, 'train_samples_per_second': 17.642, 'train_steps_per_second': 1.103, 'total_flos': 2592016957440000.0, 'train_loss': 2.55921747761388, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"./results/final_model\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:55:59.645958Z","iopub.execute_input":"2024-09-15T06:55:59.646262Z","iopub.status.idle":"2024-09-15T06:56:00.830606Z","shell.execute_reply.started":"2024-09-15T06:55:59.646228Z","shell.execute_reply":"2024-09-15T06:56:00.829497Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"!zip -r /kaggle/working/results/final_model.zip /kaggle/working/results/final_model","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:56:00.832430Z","iopub.execute_input":"2024-09-15T06:56:00.833015Z","iopub.status.idle":"2024-09-15T06:56:28.186119Z","shell.execute_reply.started":"2024-09-15T06:56:00.832959Z","shell.execute_reply":"2024-09-15T06:56:28.184711Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/results/final_model/ (stored 0%)\n  adding: kaggle/working/results/final_model/model.safetensors (deflated 7%)\n  adding: kaggle/working/results/final_model/special_tokens_map.json (deflated 74%)\n  adding: kaggle/working/results/final_model/training_args.bin (deflated 51%)\n  adding: kaggle/working/results/final_model/generation_config.json (deflated 24%)\n  adding: kaggle/working/results/final_model/merges.txt (deflated 53%)\n  adding: kaggle/working/results/final_model/config.json (deflated 52%)\n  adding: kaggle/working/results/final_model/tokenizer_config.json (deflated 55%)\n  adding: kaggle/working/results/final_model/vocab.json (deflated 68%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from safetensors.torch import load_file as load_safetensors\nmodel_name='gpt2'\nmodel_path = \"/kaggle/working/results/final_model\"\nstate_dict = load_safetensors(f\"{model_path}/model.safetensors\")\nmodel = GPT2LMHeadModel.from_pretrained(model_path, state_dict=state_dict)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:56:28.188808Z","iopub.execute_input":"2024-09-15T06:56:28.189257Z","iopub.status.idle":"2024-09-15T06:56:28.559563Z","shell.execute_reply.started":"2024-09-15T06:56:28.189206Z","shell.execute_reply":"2024-09-15T06:56:28.558393Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:56:28.560996Z","iopub.execute_input":"2024-09-15T06:56:28.561410Z","iopub.status.idle":"2024-09-15T06:56:28.979782Z","shell.execute_reply.started":"2024-09-15T06:56:28.561362Z","shell.execute_reply":"2024-09-15T06:56:28.978811Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Set pad_token to eos_token if it's not already set\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:56:28.983194Z","iopub.execute_input":"2024-09-15T06:56:28.983779Z","iopub.status.idle":"2024-09-15T06:56:28.989122Z","shell.execute_reply.started":"2024-09-15T06:56:28.983743Z","shell.execute_reply":"2024-09-15T06:56:28.988073Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def generate_text(sequence, max_new_tokens=50):\n    # Encode the input sequence and move it to the correct device\n    inputs = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True)\n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs.get('attention_mask', None).to(device)  # Get attention mask if available\n\n    # Ensure the model is on the same device\n    model.to(device)\n\n    # Generate text with the model\n    try:\n        output = model.generate(\n            input_ids,\n            attention_mask=attention_mask,\n            do_sample=True,\n            max_length=input_ids.size(1) + max_new_tokens,\n            pad_token_id=tokenizer.pad_token_id,  # Ensure this is set correctly\n            temperature=1.0,  # Control randomness\n            top_k=50,        # Control diversity\n            top_p=0.95       # Control diversity\n        )\n        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n        return generated_text\n    except Exception as e:\n        print(f\"Error during text generation: {e}\")\n        return \"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T06:56:28.990692Z","iopub.execute_input":"2024-09-15T06:56:28.991150Z","iopub.status.idle":"2024-09-15T06:56:29.002257Z","shell.execute_reply.started":"2024-09-15T06:56:28.991099Z","shell.execute_reply":"2024-09-15T06:56:29.001243Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def question_answer(question, max_new_tokens=50):\n    # Ensure the model is in evaluation mode and on the correct device\n    model.eval()\n    model.to(device)  # Move model to the correct device (GPU or CPU)\n    \n    # Prepare the input prompt\n    prompt = f\"Question: {question} Answer:\"\n    \n    # Tokenize the prompt and ensure the tensors are on the same device as the model\n    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(device)\n    \n    try:\n        # Generate the output from the model\n        output = model.generate(\n            input_ids=inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            max_length=inputs['input_ids'].size(1) + max_new_tokens,\n            pad_token_id=tokenizer.pad_token_id,\n            temperature=1.0,\n            top_k=50,\n            top_p=0.95,\n            do_sample=True  # Enable sampling for top_k and top_p to work\n        )\n\n        # Decode the generated output\n        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n        \n        # Extract only the answer from the generated text\n        generated_answer = generated_text.replace(f\"Question: {question} Answer:\", \"\").strip()\n        return generated_answer\n    except Exception as e:\n        print(f\"Error during text generation: {e}\")\n        return \"\"\n\nprint(question_answer(\"What is feature engineering for unstructured data?\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:03:24.624670Z","iopub.execute_input":"2024-09-15T07:03:24.625703Z","iopub.status.idle":"2024-09-15T07:03:25.592852Z","shell.execute_reply.started":"2024-09-15T07:03:24.625659Z","shell.execute_reply":"2024-09-15T07:03:25.591800Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"feature engineering for unstructured data involves finding and refining techniques and techniques that improve human performance in complex tasks requiring detailed metrics or data access without compromising human skills in general knowledge or ability to process data efficiently or perform tasks complex enough for humans to capture and\n","output_type":"stream"}]},{"cell_type":"code","source":"question_answer('What is the mean absolute error (MAE)?')","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:03:41.079666Z","iopub.execute_input":"2024-09-15T07:03:41.080037Z","iopub.status.idle":"2024-09-15T07:03:41.616865Z","shell.execute_reply.started":"2024-09-15T07:03:41.080005Z","shell.execute_reply":"2024-09-15T07:03:41.615691Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'answer the mean absolute error describes the probability of the predicted results with respect to both the sample and its nearest neighbor the standard deviation or variance of the prediction in a given sample it is a measure of how well predicted the predicted results are expressed in the data'"},"metadata":{}}]},{"cell_type":"code","source":"print(question_answer('What is Q-Learning and how does it work?'))","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:03:47.229675Z","iopub.execute_input":"2024-09-15T07:03:47.230399Z","iopub.status.idle":"2024-09-15T07:03:47.767479Z","shell.execute_reply.started":"2024-09-15T07:03:47.230356Z","shell.execute_reply":"2024-09-15T07:03:47.766361Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Qlearning uses a series of computer algorithms to learn the structure and context of data and models used in scientific data analysis projects where the models come into play as the data becomes more efficient. Qlearning models the human brain during natural language processing in order to\n","output_type":"stream"}]},{"cell_type":"code","source":"question_answer('What is the difference between BERT and RoBERTa?')","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:03:50.854308Z","iopub.execute_input":"2024-09-15T07:03:50.855217Z","iopub.status.idle":"2024-09-15T07:03:51.412825Z","shell.execute_reply.started":"2024-09-15T07:03:50.855171Z","shell.execute_reply":"2024-09-15T07:03:51.411491Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'answer Bert is the simplest model for extracting data from text using a binary representation while robert is simpler and simpler for extracting data from a regularization process using either bert or robert but different functions for text generation and analysis in both cases are'"},"metadata":{}}]},{"cell_type":"code","source":"question_answer(\"What is the primary function of a Generative Adversarial Network (GAN)?\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:03:53.444150Z","iopub.execute_input":"2024-09-15T07:03:53.444572Z","iopub.status.idle":"2024-09-15T07:03:53.981923Z","shell.execute_reply.started":"2024-09-15T07:03:53.444534Z","shell.execute_reply":"2024-09-15T07:03:53.980849Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'answer a primary function is the ability of a network to process information from a sequence to produce a unique and meaningful output by applying a high degree of precision to the sequence that can be used for semantic modeling or to learn the relationships between words and actions through'"},"metadata":{}}]},{"cell_type":"code","source":"question_answer(\"What Optimization Algorithms are available in Scikit-Learn?\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:04:26.480130Z","iopub.execute_input":"2024-09-15T07:04:26.480568Z","iopub.status.idle":"2024-09-15T07:04:27.012470Z","shell.execute_reply.started":"2024-09-15T07:04:26.480517Z","shell.execute_reply":"2024-09-15T07:04:27.011244Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'Optimization algorithms for deep learning are common among other algorithms including nlp and rote learning which are available under the Scikit umbrella and available under different technologies including neural network gated computing tools and reinforcement learning tools as well as through other neural networks ('"},"metadata":{}}]},{"cell_type":"code","source":"# Ensure the clean_answer function is defined\ndef clean_answer(answer):\n    return answer.strip().lower()\n\n# Generate predictions for the test set\npredicted_answers = [question_answer(q, max_new_tokens=50) for q in test_questions]\n\n# Clean test answers\ntest_answers_cleaned = [clean_answer(a) for a in test_answers]\n\n# Check if the lengths match\nif len(predicted_answers) == len(test_answers_cleaned):\n    # Compute ROUGE scores\n    rouge_results = rouge.compute(predictions=predicted_answers, references=test_answers_cleaned)\n    \n    # Display ROUGE Scores\n    print(\"ROUGE Scores:\")\n    for rouge_type, score in rouge_results.items():\n        print(f\"{rouge_type}: {score}\")\nelse:\n    print(\"Error: The number of predicted answers and test answers do not match.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:13:46.764467Z","iopub.execute_input":"2024-09-15T07:13:46.764947Z","iopub.status.idle":"2024-09-15T07:15:50.354105Z","shell.execute_reply.started":"2024-09-15T07:13:46.764904Z","shell.execute_reply":"2024-09-15T07:15:50.353181Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"ROUGE Scores:\nrouge1: 0.2385221287321419\nrouge2: 0.06923877974548409\nrougeL: 0.19462264064174561\nrougeLsum: 0.1944902155357165\n","output_type":"stream"}]},{"cell_type":"markdown","source":"[Download File](sandbox:/kaggle/working/results/final_model.zip)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
